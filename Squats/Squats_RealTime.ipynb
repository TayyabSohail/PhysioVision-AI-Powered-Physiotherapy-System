{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8d9297-8ae9-4fb9-a492-21a4d62c8331",
   "metadata": {},
   "source": [
    "### ignore (past implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa1d1c-6638-4579-94d4-1dc3aa503925",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import math\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fa330d-0790-4603-b547-37faeb09c463",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RealTimeSquatErrorDetector:\n",
    "    \"\"\"\n",
    "    Class for real-time squat error detection\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, scaler_path, label_encoder_path, window_size=30):\n",
    "        \"\"\"\n",
    "        Initialize the detector\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        model_path : str\n",
    "            Path to the saved model\n",
    "        scaler_path : str\n",
    "            Path to the saved scaler\n",
    "        label_encoder_path : str\n",
    "            Path to the saved label encoder\n",
    "        window_size : int\n",
    "            Size of the sliding window\n",
    "        \"\"\"\n",
    "        # Load model and preprocessing objects\n",
    "        self.model = load_model(model_path)\n",
    "        self.scaler = joblib.load(scaler_path)\n",
    "        self.label_encoder = joblib.load(label_encoder_path)\n",
    "        \n",
    "        # Initialize buffer\n",
    "        self.window_size = window_size\n",
    "        self.buffer = []\n",
    "        \n",
    "        # Prepare feature names (needed for preprocessing)\n",
    "        self.feature_names = [col for col in self.scaler.feature_names_in_ \n",
    "                             if not col.endswith('_velocity')]\n",
    "        \n",
    "        # Print initialization info\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "        print(f\"Model expects features: {self.feature_names}\")\n",
    "        print(f\"Detecting classes: {self.label_encoder.classes_}\")\n",
    "    \n",
    "    def preprocess_frame(self, keypoints_dict):\n",
    "        \"\"\"\n",
    "        Preprocess a single frame of keypoints\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        keypoints_dict : dict\n",
    "            Dictionary of keypoints {joint_name_x: value, joint_name_y: value, ...}\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        features : np.array\n",
    "            Extracted features for this frame\n",
    "        \"\"\"\n",
    "        # Convert keypoints to a dataframe with a single row\n",
    "        df = pd.DataFrame([keypoints_dict])\n",
    "        \n",
    "        # Extract angles (same as in preprocessing pipeline)\n",
    "        # This is a simplified version - in production you'd reuse your angle extraction code\n",
    "        # For brevity, I'm assuming the extraction happens here\n",
    "        \n",
    "        # Placeholder for extracted features\n",
    "        extracted_features = extract_angles_from_frame(df)\n",
    "        \n",
    "        return extracted_features\n",
    "    \n",
    "    def update_buffer(self, features):\n",
    "        \"\"\"\n",
    "        Update the sliding window buffer with new features\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        features : np.array\n",
    "            Features for the current frame\n",
    "        \"\"\"\n",
    "        # Add new features to buffer\n",
    "        self.buffer.append(features)\n",
    "        \n",
    "        # Keep buffer at fixed size\n",
    "        if len(self.buffer) > self.window_size:\n",
    "            self.buffer.pop(0)\n",
    "    \n",
    "    def detect_errors(self, keypoints_dict):\n",
    "        \"\"\"\n",
    "        Detect squat errors from a new frame of keypoints\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        keypoints_dict : dict\n",
    "            Dictionary of keypoints {joint_name_x: value, joint_name_y: value, ...}\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        prediction : str\n",
    "            Predicted error class or 'good'\n",
    "        confidence : float\n",
    "            Confidence score for the prediction\n",
    "        \"\"\"\n",
    "        # Preprocess frame\n",
    "        features = self.preprocess_frame(keypoints_dict)\n",
    "        \n",
    "        # Update buffer\n",
    "        self.update_buffer(features)\n",
    "        \n",
    "        # Only make prediction if buffer is full\n",
    "        if len(self.buffer) == self.window_size:\n",
    "            # Convert buffer to numpy array\n",
    "            X = np.array(self.buffer)\n",
    "            \n",
    "            # Normalize features\n",
    "            X_normalized = self.scaler.transform(X)\n",
    "            \n",
    "            # Reshape for LSTM input [samples, time steps, features]\n",
    "            X_reshaped = X_normalized.reshape(1, self.window_size, -1)\n",
    "            \n",
    "            # Make prediction\n",
    "            y_proba = self.model.predict(X_reshaped, verbose=0)[0]\n",
    "            predicted_class = np.argmax(y_proba)\n",
    "            confidence = y_proba[predicted_class]\n",
    "            \n",
    "            # Convert to class name\n",
    "            prediction = self.label_encoder.classes_[predicted_class]\n",
    "            \n",
    "            return prediction, confidence\n",
    "        else:\n",
    "            # Not enough frames yet\n",
    "            return \"Collecting frames...\", 0.0\n",
    "\n",
    "def extract_angles_from_frame(keypoints_dict):\n",
    "    \"\"\"\n",
    "    Extract angles from a single frame of keypoints for real-time processing\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    keypoints_dict : dict\n",
    "        Dictionary containing keypoint coordinates\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    features : np.array\n",
    "        Array of extracted angle features\n",
    "    \"\"\"\n",
    "    # Convert single keypoint dictionary to a properly structured pandas DataFrame\n",
    "    df = pd.DataFrame([keypoints_dict])\n",
    "    \n",
    "    # Create empty dictionary to store extracted angles\n",
    "    angles = {}\n",
    "    \n",
    "    # Define function to calculate vector between two points\n",
    "    def calc_vector(point1, point2):\n",
    "        vec = np.zeros(3)\n",
    "        vec[0] = df[f'{point2}_x'].values[0] - df[f'{point1}_x'].values[0]\n",
    "        vec[1] = df[f'{point2}_y'].values[0] - df[f'{point1}_y'].values[0]\n",
    "        vec[2] = df[f'{point2}_z'].values[0] - df[f'{point1}_z'].values[0]\n",
    "        return vec\n",
    "    \n",
    "    # Define function to normalize vector\n",
    "    def normalize_vector(vec):\n",
    "        magnitude = np.sqrt(np.sum(vec**2))\n",
    "        if magnitude < 1e-10:  # Avoid division by zero\n",
    "            magnitude = 1e-10\n",
    "        return vec / magnitude\n",
    "    \n",
    "    # Define function to calculate angle between vectors\n",
    "    def angle_between(vec1, vec2):\n",
    "        vec1_norm = normalize_vector(vec1)\n",
    "        vec2_norm = normalize_vector(vec2)\n",
    "        dot_product = np.sum(vec1_norm * vec2_norm)\n",
    "        # Clip to avoid domain errors due to floating point precision\n",
    "        dot_product = np.clip(dot_product, -1.0, 1.0)\n",
    "        return np.degrees(np.arccos(dot_product))\n",
    "    \n",
    "    # Calculate vectors\n",
    "    # Torso vectors\n",
    "    shoulder_to_hip_left = calc_vector('LEFT_SHOULDER', 'LEFT_HIP')\n",
    "    shoulder_to_hip_right = calc_vector('RIGHT_SHOULDER', 'RIGHT_HIP')\n",
    "    \n",
    "    # Thigh vectors\n",
    "    hip_to_knee_left = calc_vector('LEFT_HIP', 'LEFT_KNEE')\n",
    "    hip_to_knee_right = calc_vector('RIGHT_HIP', 'RIGHT_KNEE')\n",
    "    \n",
    "    # Shin vectors\n",
    "    knee_to_ankle_left = calc_vector('LEFT_KNEE', 'LEFT_ANKLE')\n",
    "    knee_to_ankle_right = calc_vector('RIGHT_KNEE', 'RIGHT_ANKLE')\n",
    "    \n",
    "    # Head vector\n",
    "    nose_to_shoulder_mid = calc_vector('NOSE', 'LEFT_SHOULDER')\n",
    "    \n",
    "    # Calculate angles\n",
    "    # Knee angles (shin to thigh)\n",
    "    angles['left_knee_angle'] = angle_between(hip_to_knee_left, knee_to_ankle_left)\n",
    "    angles['right_knee_angle'] = angle_between(hip_to_knee_right, knee_to_ankle_right)\n",
    "    \n",
    "    # Hip angles (torso to thigh)\n",
    "    angles['left_hip_angle'] = angle_between(shoulder_to_hip_left, hip_to_knee_left)\n",
    "    angles['right_hip_angle'] = angle_between(shoulder_to_hip_right, hip_to_knee_right)\n",
    "    \n",
    "    # Back angles (relative to vertical)\n",
    "    vertical = np.array([0, 1, 0])  # Y axis is usually vertical in pose estimation\n",
    "    angles['torso_vertical_angle'] = angle_between(shoulder_to_hip_left, vertical)\n",
    "    \n",
    "    # Head angle relative to torso\n",
    "    angles['head_torso_angle'] = angle_between(nose_to_shoulder_mid, shoulder_to_hip_left)\n",
    "    \n",
    "    # Knee distance (for detecting knee valgus/varus)\n",
    "    hip_width = np.sqrt(\n",
    "        (df['RIGHT_HIP_x'].values[0] - df['LEFT_HIP_x'].values[0])**2 + \n",
    "        (df['RIGHT_HIP_z'].values[0] - df['LEFT_HIP_z'].values[0])**2\n",
    "    )\n",
    "    knee_distance = np.sqrt(\n",
    "        (df['RIGHT_KNEE_x'].values[0] - df['LEFT_KNEE_x'].values[0])**2 + \n",
    "        (df['RIGHT_KNEE_z'].values[0] - df['LEFT_KNEE_z'].values[0])**2\n",
    "    )\n",
    "    angles['knee_distance_normalized'] = knee_distance / hip_width if hip_width > 0 else 0\n",
    "    \n",
    "    # Foot positioning (relevant for toe angle issues)\n",
    "    ankle_distance = np.sqrt(\n",
    "        (df['RIGHT_ANKLE_x'].values[0] - df['LEFT_ANKLE_x'].values[0])**2 + \n",
    "        (df['RIGHT_ANKLE_z'].values[0] - df['LEFT_ANKLE_z'].values[0])**2\n",
    "    )\n",
    "    angles['ankle_distance_normalized'] = ankle_distance / hip_width if hip_width > 0 else 0\n",
    "    \n",
    "    # Squat depth - hip height relative to knee height\n",
    "    angles['left_squat_depth'] = df['LEFT_HIP_y'].values[0] - df['LEFT_KNEE_y'].values[0]\n",
    "    angles['right_squat_depth'] = df['RIGHT_HIP_y'].values[0] - df['RIGHT_KNEE_y'].values[0]\n",
    "    \n",
    "    # Convert angles dictionary to a pandas Series and then to a numpy array\n",
    "    features = pd.Series(angles).values\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "703a0339-c7a5-43c8-975b-a0cd36387aff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3019c32-d3b8-4f5e-a4f1-18678ba975f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MediaPipePoseFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize MediaPipe pose detection and setup landmark mapping\n",
    "        \"\"\"\n",
    "        # Initialize MediaPipe Pose\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=2,  # Use highest accuracy model\n",
    "            smooth_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Define mapping from MediaPipe landmarks to our keypoint format\n",
    "        self.landmark_mapping = {\n",
    "            # Format: our_keypoint_name: mediapipe_landmark_index\n",
    "            'LEFT_SHOULDER': self.mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "            'RIGHT_SHOULDER': self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "            'LEFT_HIP': self.mp_pose.PoseLandmark.LEFT_HIP.value,\n",
    "            'RIGHT_HIP': self.mp_pose.PoseLandmark.RIGHT_HIP.value,\n",
    "            'LEFT_KNEE': self.mp_pose.PoseLandmark.LEFT_KNEE.value,\n",
    "            'RIGHT_KNEE': self.mp_pose.PoseLandmark.RIGHT_KNEE.value,\n",
    "            'LEFT_ANKLE': self.mp_pose.PoseLandmark.LEFT_ANKLE.value,\n",
    "            'RIGHT_ANKLE': self.mp_pose.PoseLandmark.RIGHT_ANKLE.value,\n",
    "            'NOSE': self.mp_pose.PoseLandmark.NOSE.value,\n",
    "        }\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Process a video frame with MediaPipe and extract pose landmarks\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        frame : np.array\n",
    "            RGB video frame\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        keypoints_dict : dict\n",
    "            Dictionary of keypoint coordinates compatible with our model\n",
    "        landmarks : list or None\n",
    "            Raw MediaPipe landmark results for visualization\n",
    "        \"\"\"\n",
    "        # Convert BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame with MediaPipe\n",
    "        results = self.pose.process(frame_rgb)\n",
    "        \n",
    "        # If no pose detected, return None\n",
    "        if not results.pose_landmarks:\n",
    "            return None, None\n",
    "        \n",
    "        # Extract landmarks and convert to our keypoint format\n",
    "        keypoints_dict = self._landmarks_to_keypoint_dict(results.pose_landmarks.landmark, frame.shape)\n",
    "        \n",
    "        return keypoints_dict, results.pose_landmarks\n",
    "    \n",
    "    def _landmarks_to_keypoint_dict(self, landmarks, frame_shape):\n",
    "        \"\"\"\n",
    "        Convert MediaPipe landmarks to our keypoint dictionary format\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        landmarks : list\n",
    "            MediaPipe landmark results\n",
    "        frame_shape : tuple\n",
    "            Shape of the video frame (height, width, channels)\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        keypoints_dict : dict\n",
    "            Dictionary of keypoint coordinates compatible with our model\n",
    "        \"\"\"\n",
    "        height, width, _ = frame_shape\n",
    "        keypoints_dict = {}\n",
    "        \n",
    "        # Extract coordinates for each keypoint\n",
    "        for our_name, mp_idx in self.landmark_mapping.items():\n",
    "            landmark = landmarks[mp_idx]\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            x = landmark.x * width\n",
    "            y = landmark.y * height\n",
    "            z = landmark.z * width  # Z is relative to width for reasonable scale\n",
    "            \n",
    "            # Store in our format\n",
    "            keypoints_dict[f'{our_name}_x'] = x\n",
    "            keypoints_dict[f'{our_name}_y'] = y\n",
    "            keypoints_dict[f'{our_name}_z'] = z\n",
    "        \n",
    "        return keypoints_dict\n",
    "    \n",
    "    def draw_landmarks(self, frame, landmarks):\n",
    "        \"\"\"\n",
    "        Draw the pose landmarks on the frame\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        frame : np.array\n",
    "            BGR video frame\n",
    "        landmarks : mediapipe pose landmarks\n",
    "            Landmarks to draw\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        annotated_frame : np.array\n",
    "            Frame with landmarks drawn\n",
    "        \"\"\"\n",
    "        if landmarks:\n",
    "            mp_drawing = mp.solutions.drawing_utils\n",
    "            mp_drawing_styles = mp.solutions.drawing_styles\n",
    "            \n",
    "            # Draw pose landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                landmarks,\n",
    "                self.mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def release(self):\n",
    "        \"\"\"\n",
    "        Release MediaPipe resources\n",
    "        \"\"\"\n",
    "        self.pose.close()\n",
    "\n",
    "\n",
    "def real_time_squat_detection(model_path='./best_squat_model.keras', \n",
    "                             scaler_path='./preprocessed_data_scaler.joblib',\n",
    "                             label_encoder_path='./preprocessed_data_label_encoder.joblib',\n",
    "                             camera_id=0):\n",
    "    \"\"\"\n",
    "    Run real-time squat detection using webcam feed\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Path to trained LSTM model\n",
    "    scaler_path : str\n",
    "        Path to fitted StandardScaler\n",
    "    label_encoder_path : str\n",
    "        Path to fitted LabelEncoder\n",
    "    camera_id : int\n",
    "        Camera ID for OpenCV\n",
    "    \"\"\"\n",
    "    # Import here to avoid issues if user doesn't want to run this function\n",
    "    #from real_time_error_detector import RealTimeSquatErrorDetector\n",
    "    \n",
    "    # Initialize MediaPipe feature extractor\n",
    "    extractor = MediaPipePoseFeatureExtractor()\n",
    "    \n",
    "    # Initialize squat error detector\n",
    "    detector = RealTimeSquatErrorDetector(\n",
    "        model_path=model_path,\n",
    "        scaler_path=scaler_path,\n",
    "        label_encoder_path=label_encoder_path\n",
    "    )\n",
    "    \n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        # Process frame with MediaPipe\n",
    "        keypoints_dict, landmarks = extractor.process_frame(frame)\n",
    "        \n",
    "        if keypoints_dict:\n",
    "            # Get error prediction\n",
    "            prediction, confidence = detector.detect_errors(keypoints_dict)\n",
    "            \n",
    "            # Draw prediction on frame\n",
    "            text = f\"{prediction} ({confidence:.2f})\"\n",
    "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                       (0, 255, 0) if prediction == 'good' else (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No pose detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                       (0, 0, 255), 2)\n",
    "        \n",
    "        # Draw landmarks on frame\n",
    "        frame = extractor.draw_landmarks(frame, landmarks)\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Squat Form Analysis', frame)\n",
    "        \n",
    "        # Exit on 'q' press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    extractor.release()\n",
    "\n",
    "\n",
    "def process_video_file(video_path, output_path=None,\n",
    "                      model_path='./best_squat_model.keras', \n",
    "                      scaler_path='./preprocessed_data_scaler.joblib',\n",
    "                      label_encoder_path='./preprocessed_data_label_encoder.joblib'):\n",
    "    \"\"\"\n",
    "    Process a video file for squat form analysis\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    video_path : str\n",
    "        Path to input video file\n",
    "    output_path : str or None\n",
    "        Path to save output video (if None, won't save)\n",
    "    model_path : str\n",
    "        Path to trained LSTM model\n",
    "    scaler_path : str\n",
    "        Path to fitted StandardScaler\n",
    "    label_encoder_path : str\n",
    "        Path to fitted LabelEncoder\n",
    "    \"\"\"\n",
    "    # Import here to avoid issues if user doesn't want to run this function\n",
    "    #from real_time_error_detector import RealTimeSquatErrorDetector\n",
    "    \n",
    "    # Initialize MediaPipe feature extractor\n",
    "    extractor = MediaPipePoseFeatureExtractor()\n",
    "    \n",
    "    # Initialize squat error detector\n",
    "    detector = RealTimeSquatErrorDetector(\n",
    "        model_path=model_path,\n",
    "        scaler_path=scaler_path,\n",
    "        label_encoder_path=label_encoder_path\n",
    "    )\n",
    "    \n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Initialize video writer if output path provided\n",
    "    writer = None\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Process video frame by frame\n",
    "    frame_count = 0\n",
    "    predictions = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process frame with MediaPipe\n",
    "        keypoints_dict, landmarks = extractor.process_frame(frame)\n",
    "        \n",
    "        if keypoints_dict:\n",
    "            # Get error prediction\n",
    "            prediction, confidence = detector.detect_errors(keypoints_dict)\n",
    "            predictions.append((frame_count, prediction, confidence))\n",
    "            \n",
    "            # Draw prediction on frame\n",
    "            text = f\"{prediction} ({confidence:.2f})\"\n",
    "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                       (0, 255, 0) if prediction == 'good' else (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No pose detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                       (0, 0, 255), 2)\n",
    "        \n",
    "        # Draw landmarks on frame\n",
    "        frame = extractor.draw_landmarks(frame, landmarks)\n",
    "        \n",
    "        # Write frame if output path provided\n",
    "        if writer:\n",
    "            writer.write(frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Show progress every 100 frames\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processed {frame_count} frames\")\n",
    "    \n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    if writer:\n",
    "        writer.close()\n",
    "    extractor.release()\n",
    "    \n",
    "    # Create analysis dataframe\n",
    "    if predictions:\n",
    "        analysis_df = pd.DataFrame(predictions, columns=['frame', 'prediction', 'confidence'])\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nAnalysis Summary:\")\n",
    "        print(f\"Total frames analyzed: {frame_count}\")\n",
    "        print(\"\\nError distribution:\")\n",
    "        error_counts = analysis_df['prediction'].value_counts()\n",
    "        for error, count in error_counts.items():\n",
    "            percentage = count / len(analysis_df) * 100\n",
    "            print(f\"{error}: {count} frames ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Save analysis to CSV if output path provided\n",
    "        if output_path:\n",
    "            csv_path = output_path.rsplit('.', 1)[0] + '_analysis.csv'\n",
    "            analysis_df.to_csv(csv_path, index=False)\n",
    "            print(f\"\\nAnalysis saved to {csv_path}\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ef941e-fa79-4f2e-9796-72d7494f438e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./best_squat_model.keras\n",
      "Model expects features: ['left_knee_angle', 'right_knee_angle', 'left_hip_angle', 'right_hip_angle', 'torso_vertical_angle', 'head_torso_angle', 'knee_distance_normalized', 'ankle_distance_normalized', 'left_squat_depth', 'right_squat_depth']\n",
      "Detecting classes: ['bad_back_round' 'bad_back_warp' 'bad_head' 'bad_inner_thigh'\n",
      " 'bad_shallow' 'bad_toe' 'good']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(1, 1, 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# For webcam-based detection:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#real_time_squat_detection()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# For video file processing:\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     process_video_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./squat_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalyzed_squat_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 265\u001b[0m, in \u001b[0;36mprocess_video_file\u001b[1;34m(video_path, output_path, model_path, scaler_path, label_encoder_path)\u001b[0m\n\u001b[0;32m    261\u001b[0m keypoints_dict, landmarks \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mprocess_frame(frame)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keypoints_dict:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# Get error prediction\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     prediction, confidence \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect_errors(keypoints_dict)\n\u001b[0;32m    266\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend((frame_count, prediction, confidence))\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;66;03m# Draw prediction on frame\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 97\u001b[0m, in \u001b[0;36mRealTimeSquatErrorDetector.detect_errors\u001b[1;34m(self, keypoints_dict)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03mDetect squat errors from a new frame of keypoints\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Confidence score for the prediction\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Preprocess frame\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_frame(keypoints_dict)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Update buffer\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_buffer(features)\n",
      "Cell \u001b[1;32mIn[2], line 60\u001b[0m, in \u001b[0;36mRealTimeSquatErrorDetector.preprocess_frame\u001b[1;34m(self, keypoints_dict)\u001b[0m\n\u001b[0;32m     53\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([keypoints_dict])\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Extract angles (same as in preprocessing pipeline)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# This is a simplified version - in production you'd reuse your angle extraction code\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# For brevity, I'm assuming the extraction happens here\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Placeholder for extracted features\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m extracted_features \u001b[38;5;241m=\u001b[39m extract_angles_from_frame(df)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extracted_features\n",
      "Cell \u001b[1;32mIn[2], line 141\u001b[0m, in \u001b[0;36mextract_angles_from_frame\u001b[1;34m(keypoints_dict)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03mExtract angles from a single frame of keypoints for real-time processing\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m    Array of extracted angle features\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Convert single keypoint dictionary to a properly structured pandas DataFrame\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([keypoints_dict])\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Create empty dictionary to store extracted angles\u001b[39;00m\n\u001b[0;32m    144\u001b[0m angles \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\pandas\\core\\frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m             arrays,\n\u001b[0;32m    861\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    868\u001b[0m             data,\n\u001b[0;32m    869\u001b[0m             index,\n\u001b[0;32m    870\u001b[0m             columns,\n\u001b[0;32m    871\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    872\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    873\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    874\u001b[0m         )\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    877\u001b[0m         {},\n\u001b[0;32m    878\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    882\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_2d(values)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(\n\u001b[0;32m    324\u001b[0m         values,\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:582\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     values \u001b[38;5;241m=\u001b[39m convert(values)\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ensure_2d(values)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(1, 1, 27)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    # For webcam-based detection:\n",
    "    #real_time_squat_detection()\n",
    "    \n",
    "    # For video file processing:\n",
    "    process_video_file(\"./squat_video.mp4\", \"analyzed_squat_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca804a-09a7-40c5-a889-648636c41d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20fc6b8-cac1-4f9d-bfc2-7919dbb17eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b7fce-04db-4ac3-8e84-c11a173fdb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1906ec7a-4188-4c6e-b7e5-3d0cf0296cc2",
   "metadata": {},
   "source": [
    "# FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed77323a-0467-4cc6-a664-45502acded5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28faa5-d661-4fff-96f5-7266fd9f9de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c808a9d-f872-4a28-aced-b161edfda7c7",
   "metadata": {},
   "source": [
    "## Squat Analyzer Class (Loads and runs the model with mediapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40f85cd0-50d1-44e4-a770-acbfc21074d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquatAnalyzer:\n",
    "    def __init__(self, model_path, scaler_path, label_encoder_path, window_size=30):\n",
    "        \"\"\"Initialize the squat analyzer with trained model and preprocessing tools\"\"\"\n",
    "        # Load model and preprocessing tools\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.scaler = joblib.load(scaler_path)\n",
    "        self.label_encoder = joblib.load(label_encoder_path)\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Initialize MediaPipe Pose\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            model_complexity=1\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        \n",
    "        # Create buffer for storing features\n",
    "        self.features_buffer = deque(maxlen=window_size)\n",
    "        \n",
    "        # Store current prediction and confidence\n",
    "        self.current_prediction = None\n",
    "        self.prediction_confidence = 0.0\n",
    "        self.last_predictions = deque(maxlen=5)  # Store last 5 predictions for smoothing\n",
    "        \n",
    "        \n",
    "        # Feature names for the processed angles\n",
    "        self.feature_names = [\n",
    "            'left_knee_angle', 'right_knee_angle', \n",
    "            'left_hip_angle', 'right_hip_angle',\n",
    "            'torso_vertical_angle', 'head_torso_angle',\n",
    "            'knee_distance_normalized', 'ankle_distance_normalized',\n",
    "            'left_squat_depth', 'right_squat_depth',\n",
    "            'left_knee_angle_velocity', 'right_knee_angle_velocity',\n",
    "            'left_hip_angle_velocity', 'right_hip_angle_velocity',\n",
    "            'torso_vertical_angle_velocity', 'head_torso_angle_velocity',\n",
    "            'knee_distance_normalized_velocity', 'ankle_distance_normalized_velocity',\n",
    "            'left_squat_depth_velocity', 'right_squat_depth_velocity'\n",
    "        ]\n",
    "        \n",
    "        # Keypoint mapping from MediaPipe to our preprocessing format\n",
    "        self.keypoint_map = {\n",
    "            'NOSE': self.mp_pose.PoseLandmark.NOSE,\n",
    "            'LEFT_SHOULDER': self.mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
    "            'RIGHT_SHOULDER': self.mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "            'LEFT_HIP': self.mp_pose.PoseLandmark.LEFT_HIP,\n",
    "            'RIGHT_HIP': self.mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "            'LEFT_KNEE': self.mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "            'RIGHT_KNEE': self.mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "            'LEFT_ANKLE': self.mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "            'RIGHT_ANKLE': self.mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "        }\n",
    "        \n",
    "        # Error explanations\n",
    "        self.error_explanations = {\n",
    "            'bad_back_round': \"Your back is rounding. Keep your spine neutral.\",\n",
    "            'bad_back_warp': \"Your back is excessively arched. Maintain a neutral spine.\",\n",
    "            'bad_head': \"Head position incorrect. Look slightly downward, keeping your neck aligned with your spine.\",\n",
    "            'bad_inner_thigh': \"Knees collapsing inward. Keep knees aligned with toes.\",\n",
    "            'bad_shallow': \"Squat is too shallow. Try to go deeper with proper form.\",\n",
    "            'bad_toe': \"Foot positioning issue. Keep feet shoulder-width apart with toes slightly turned out.\",\n",
    "            'good': \"Good form! Keep it up.\"\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Add rep counting variables\n",
    "        self.rep_count = 0\n",
    "        self.state = 'STANDING'  # Initial state\n",
    "        self.depth_history = deque(maxlen=10)  # Store recent squat depths for dynamic thresholding\n",
    "        self.min_depth = None  # Dynamic minimum depth (updated during exercise)\n",
    "        self.max_depth = None  # Dynamic maximum depth (updated during exercise)\n",
    "        self.depth_threshold_factor = 0.5  # Percentage of depth range to consider a state change\n",
    "\n",
    "        # Add error occurrence tracking\n",
    "        self.error_counts = {\n",
    "            'bad_back_round': 0,\n",
    "            'bad_back_warp': 0,\n",
    "            'bad_head': 0,\n",
    "            'bad_inner_thigh': 0,\n",
    "            'bad_shallow': 0,\n",
    "            'bad_toe': 0,\n",
    "            'good': 0  # Track good form too\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        print(\"Squat Analyzer initialized successfully\")\n",
    "\n",
    "    def _landmarks_to_keypoints_dict(self, landmarks):\n",
    "        \"\"\"Convert MediaPipe landmarks to format compatible with preprocessing code\"\"\"\n",
    "        keypoints = {}\n",
    "        for name, landmark_id in self.keypoint_map.items():\n",
    "            landmark = landmarks.landmark[landmark_id]\n",
    "            keypoints[f'{name}_x'] = landmark.x\n",
    "            keypoints[f'{name}_y'] = landmark.y\n",
    "            keypoints[f'{name}_z'] = landmark.z\n",
    "        return keypoints\n",
    "\n",
    "    def _keypoints_dict_to_df(self, keypoints_dict):\n",
    "        \"\"\"Convert keypoints dictionary to DataFrame\"\"\"\n",
    "        return pd.DataFrame([keypoints_dict])\n",
    "\n",
    "    def _calculate_vector(self, df, point1, point2):\n",
    "        \"\"\"Calculate vector between two keypoints\"\"\"\n",
    "        vec = np.zeros((len(df), 3))\n",
    "        vec[:, 0] = df[f'{point2}_x'].values - df[f'{point1}_x'].values\n",
    "        vec[:, 1] = df[f'{point2}_y'].values - df[f'{point1}_y'].values\n",
    "        vec[:, 2] = df[f'{point2}_z'].values - df[f'{point1}_z'].values\n",
    "        return vec\n",
    "\n",
    "    def _normalize_vector(self, vec):\n",
    "        \"\"\"Normalize a vector to unit length\"\"\"\n",
    "        magnitude = np.sqrt(np.sum(vec**2, axis=1))\n",
    "        magnitude = np.where(magnitude == 0, 1e-10, magnitude)\n",
    "        vec_normalized = vec / magnitude[:, np.newaxis]\n",
    "        return vec_normalized\n",
    "\n",
    "    def _angle_between_vectors(self, vec1, vec2):\n",
    "        \"\"\"Calculate the angle between two 3D vectors in degrees\"\"\"\n",
    "        vec1_norm = self._normalize_vector(vec1)\n",
    "        vec2_norm = self._normalize_vector(vec2)\n",
    "        dot_product = np.sum(vec1_norm * vec2_norm, axis=1)\n",
    "        dot_product = np.clip(dot_product, -1.0, 1.0)\n",
    "        angles = np.degrees(np.arccos(dot_product))\n",
    "        return angles\n",
    "\n",
    "    def _extract_anatomical_angles(self, df):\n",
    "        \"\"\"Extract biomechanically relevant angles from keypoints\"\"\"\n",
    "        angles_df = pd.DataFrame()\n",
    "        \n",
    "        # Calculate vectors\n",
    "        shoulder_to_hip_left = self._calculate_vector(df, 'LEFT_SHOULDER', 'LEFT_HIP')\n",
    "        shoulder_to_hip_right = self._calculate_vector(df, 'RIGHT_SHOULDER', 'RIGHT_HIP')\n",
    "        hip_to_knee_left = self._calculate_vector(df, 'LEFT_HIP', 'LEFT_KNEE')\n",
    "        hip_to_knee_right = self._calculate_vector(df, 'RIGHT_HIP', 'RIGHT_KNEE')\n",
    "        knee_to_ankle_left = self._calculate_vector(df, 'LEFT_KNEE', 'LEFT_ANKLE')\n",
    "        knee_to_ankle_right = self._calculate_vector(df, 'RIGHT_KNEE', 'RIGHT_ANKLE')\n",
    "        nose_to_shoulder_mid = self._calculate_vector(df, 'NOSE', 'LEFT_SHOULDER')\n",
    "        \n",
    "        # Calculate angles\n",
    "        angles_df['left_knee_angle'] = self._angle_between_vectors(hip_to_knee_left, knee_to_ankle_left)\n",
    "        angles_df['right_knee_angle'] = self._angle_between_vectors(hip_to_knee_right, knee_to_ankle_right)\n",
    "        angles_df['left_hip_angle'] = self._angle_between_vectors(shoulder_to_hip_left, hip_to_knee_left)\n",
    "        angles_df['right_hip_angle'] = self._angle_between_vectors(shoulder_to_hip_right, hip_to_knee_right)\n",
    "        \n",
    "        # Back angles (relative to vertical)\n",
    "        vertical = np.zeros_like(shoulder_to_hip_left)\n",
    "        vertical[:, 1] = 1  # Y axis is usually vertical in pose estimation\n",
    "        angles_df['torso_vertical_angle'] = self._angle_between_vectors(shoulder_to_hip_left, vertical)\n",
    "        \n",
    "        # Head angle relative to torso\n",
    "        angles_df['head_torso_angle'] = self._angle_between_vectors(nose_to_shoulder_mid, shoulder_to_hip_left)\n",
    "        \n",
    "        # Knee distance (for detecting knee valgus/varus)\n",
    "        hip_width = np.sqrt(\n",
    "            (df['RIGHT_HIP_x'] - df['LEFT_HIP_x'])**2 + \n",
    "            (df['RIGHT_HIP_z'] - df['LEFT_HIP_z'])**2\n",
    "        )\n",
    "        knee_distance = np.sqrt(\n",
    "            (df['RIGHT_KNEE_x'] - df['LEFT_KNEE_x'])**2 + \n",
    "            (df['RIGHT_KNEE_z'] - df['LEFT_KNEE_z'])**2\n",
    "        )\n",
    "        angles_df['knee_distance_normalized'] = knee_distance / hip_width\n",
    "        \n",
    "        # Foot positioning\n",
    "        ankle_distance = np.sqrt(\n",
    "            (df['RIGHT_ANKLE_x'] - df['LEFT_ANKLE_x'])**2 + \n",
    "            (df['RIGHT_ANKLE_z'] - df['LEFT_ANKLE_z'])**2\n",
    "        )\n",
    "        angles_df['ankle_distance_normalized'] = ankle_distance / hip_width\n",
    "        \n",
    "        # Squat depth - hip height relative to knee height\n",
    "        angles_df['left_squat_depth'] = df['LEFT_HIP_y'] - df['LEFT_KNEE_y']\n",
    "        angles_df['right_squat_depth'] = df['RIGHT_HIP_y'] - df['RIGHT_KNEE_y']\n",
    "        \n",
    "        return angles_df\n",
    "\n",
    "    def _add_velocity_features(self, current_features, prev_features=None, fps=30):\n",
    "        \"\"\"Add velocity features based on frame-to-frame changes\"\"\"\n",
    "        velocity_features = {}\n",
    "        \n",
    "        if prev_features is None:\n",
    "            # No previous frame, set velocities to 0\n",
    "            for column in current_features.index:\n",
    "                velocity_features[f'{column}_velocity'] = 0\n",
    "        else:\n",
    "            # Calculate frame-to-frame changes\n",
    "            for column in current_features.index:\n",
    "                velocity_features[f'{column}_velocity'] = (current_features[column] - prev_features[column]) * fps\n",
    "                \n",
    "        # Combine with current features\n",
    "        all_features = {}\n",
    "        for column in current_features.index:\n",
    "            all_features[column] = current_features[column]\n",
    "        all_features.update(velocity_features)\n",
    "        \n",
    "        return pd.Series(all_features)\n",
    "\n",
    "    def _process_frame(self, frame):\n",
    "        \"\"\"Process a single frame and extract features\"\"\"\n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image\n",
    "        results = self.pose.process(image_rgb)\n",
    "        \n",
    "        # If no pose detected, return None\n",
    "        if not results.pose_landmarks:\n",
    "            return None, frame\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = frame.copy()\n",
    "        self.mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            results.pose_landmarks,\n",
    "            self.mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        \n",
    "        # Convert landmarks to keypoints dictionary\n",
    "        keypoints_dict = self._landmarks_to_keypoints_dict(results.pose_landmarks)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        keypoints_df = self._keypoints_dict_to_df(keypoints_dict)\n",
    "        \n",
    "        # Extract angles\n",
    "        angles_df = self._extract_anatomical_angles(keypoints_df)\n",
    "        \n",
    "        # Get the first row as a Series\n",
    "        feature_series = angles_df.iloc[0]\n",
    "        \n",
    "        # Add velocity features if we have previous features\n",
    "        if len(self.features_buffer) > 0:\n",
    "            prev_features = self.features_buffer[-1]\n",
    "            feature_series = self._add_velocity_features(feature_series, prev_features)\n",
    "        else:\n",
    "            # No previous features, add zero velocities\n",
    "            feature_series = self._add_velocity_features(feature_series)\n",
    "        \n",
    "        # Add to buffer\n",
    "        self.features_buffer.append(feature_series)\n",
    "        \n",
    "        return feature_series, annotated_image\n",
    "\n",
    "    def _make_prediction(self):\n",
    "        \"\"\"Make a prediction using the current feature buffer\"\"\"\n",
    "        if len(self.features_buffer) < self.window_size:\n",
    "            return None, 0.0\n",
    "        \n",
    "        # Prepare features for model input\n",
    "        features_array = np.array([feature[self.feature_names] for feature in self.features_buffer])\n",
    "        \n",
    "        # Apply scaler transformation (same as in training)\n",
    "        normalized_features = self.scaler.transform(features_array)\n",
    "        \n",
    "        # Reshape for model input [batch_size=1, window_size, num_features]\n",
    "        model_input = normalized_features.reshape(1, self.window_size, len(self.feature_names))\n",
    "        \n",
    "        # Get prediction\n",
    "        prediction_probs = self.model.predict(model_input, verbose=0)[0]\n",
    "        predicted_class_idx = np.argmax(prediction_probs)\n",
    "        confidence = prediction_probs[predicted_class_idx]\n",
    "        \n",
    "        # Get class name\n",
    "        predicted_class = self.label_encoder.classes_[predicted_class_idx]\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "\n",
    "    def _smooth_predictions(self, new_prediction, new_confidence):\n",
    "        \"\"\"Smooth predictions to avoid flickering\"\"\"\n",
    "        if new_prediction is None:\n",
    "            return self.current_prediction, self.prediction_confidence\n",
    "        \n",
    "        # Add to recent predictions\n",
    "        self.last_predictions.append((new_prediction, new_confidence))\n",
    "        \n",
    "        # Count occurrences of each prediction\n",
    "        prediction_counts = {}\n",
    "        total_confidence = {}\n",
    "        \n",
    "        for pred, conf in self.last_predictions:\n",
    "            if pred not in prediction_counts:\n",
    "                prediction_counts[pred] = 0\n",
    "                total_confidence[pred] = 0\n",
    "            \n",
    "            prediction_counts[pred] += 1\n",
    "            total_confidence[pred] += conf\n",
    "        \n",
    "        # Get the most common prediction\n",
    "        if prediction_counts:\n",
    "            most_common = max(prediction_counts.items(), key=lambda x: x[1])[0]\n",
    "            avg_confidence = total_confidence[most_common] / prediction_counts[most_common]\n",
    "            return most_common, avg_confidence\n",
    "        \n",
    "        return None, 0.0\n",
    "\n",
    "\n",
    "\n",
    "    def _update_rep_count(self, current_depth):\n",
    "        \"\"\"Update squat state and count reps based on squat depth\"\"\"\n",
    "        # Use average of left and right squat depth for consistency\n",
    "        avg_depth = (current_depth['left_squat_depth'] + current_depth['right_squat_depth']) / 2\n",
    "        self.depth_history.append(avg_depth)\n",
    "\n",
    "        # Update min and max depths dynamically\n",
    "        if len(self.depth_history) == self.depth_history.maxlen:\n",
    "            current_min = min(self.depth_history)\n",
    "            current_max = max(self.depth_history)\n",
    "            \n",
    "            if self.min_depth is None or current_min < self.min_depth:\n",
    "                self.min_depth = current_min\n",
    "            if self.max_depth is None or current_max > self.max_depth:\n",
    "                self.max_depth = current_max\n",
    "\n",
    "            # Calculate dynamic threshold\n",
    "            if self.min_depth is not None and self.max_depth is not None:\n",
    "                depth_range = self.max_depth - self.min_depth\n",
    "                threshold = self.min_depth + (depth_range * self.depth_threshold_factor)\n",
    "\n",
    "                # State transitions\n",
    "                if self.state == 'STANDING' and avg_depth < threshold:\n",
    "                    self.state = 'SQUATTING'\n",
    "                elif self.state == 'SQUATTING' and avg_depth > threshold:\n",
    "                    self.state = 'STANDING'\n",
    "                    self.rep_count += 1  # Count a rep when returning to standing\n",
    "\n",
    "    def _update_error_counts(self, prediction):\n",
    "        \"\"\"Update the count of the current prediction/error\"\"\"\n",
    "        if prediction in self.error_counts:\n",
    "            self.error_counts[prediction] += 1\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def draw_feedback(self, image, prediction, confidence):\n",
    "        h, w, _ = image.shape\n",
    "        \n",
    "        # Background for text (make it larger to fit rep counter)\n",
    "        cv2.rectangle(image, (0, h-140), (w, h), (0, 0, 0), -1)\n",
    "        \n",
    "        # Draw form feedback (existing code)\n",
    "        if prediction is None:\n",
    "            cv2.putText(image, \"Getting ready...\", (10, h-100), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        else:\n",
    "            # Determine text color based on prediction\n",
    "            if prediction == 'good':\n",
    "                text_color = (0, 255, 0)  # Green for good form\n",
    "            else:\n",
    "                text_color = (0, 0, 255)  # Red for errors\n",
    "            \n",
    "            # Add prediction and confidence\n",
    "            cv2.putText(image, f\"Form: {prediction}\", (10, h-100), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n",
    "            cv2.putText(image, f\"Confidence: {confidence:.2f}\", (10, h-70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n",
    "            \n",
    "            # Add explanation for errors\n",
    "            if prediction in self.error_explanations:\n",
    "                explanation = self.error_explanations[prediction]\n",
    "                cv2.putText(image, explanation, (w//4, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, text_color, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Add rep count display\n",
    "        cv2.putText(image, f\"Reps: {self.rep_count}\", (10, h-40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate a report summarizing reps and error occurrences\"\"\"\n",
    "        report = f\"Squat Analysis Report - {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "        report += \"=\" * 50 + \"\\n\"\n",
    "        report += f\"Total Reps Performed: {self.rep_count}\\n\\n\"\n",
    "        report += \"Form Analysis:\\n\"\n",
    "        report += \"-\" * 20 + \"\\n\"\n",
    "        \n",
    "        total_frames_with_prediction = sum(self.error_counts.values())\n",
    "        if total_frames_with_prediction > 0:\n",
    "            for error, count in self.error_counts.items():\n",
    "                percentage = (count / total_frames_with_prediction) * 100\n",
    "                explanation = self.error_explanations.get(error, \"No explanation available\")\n",
    "                report += f\"{error}: {count} occurrences ({percentage:.1f}%)\\n\"\n",
    "                report += f\"  - {explanation}\\n\"\n",
    "        else:\n",
    "            report += \"No form predictions recorded.\\n\"\n",
    "        \n",
    "        report += \"=\" * 50\n",
    "        return report\n",
    "\n",
    "    def reset_counters(self):\n",
    "        \"\"\"Reset rep count and error counts\"\"\"\n",
    "        self.rep_count = 0\n",
    "        self.state = 'STANDING'\n",
    "        self.depth_history.clear()\n",
    "        self.min_depth = None\n",
    "        self.max_depth = None\n",
    "        for error in self.error_counts:\n",
    "            self.error_counts[error] = 0\n",
    "        print(\"Counters reset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def rescale_frame(self, frame, scale_percent=50):\n",
    "        \"\"\"\n",
    "        Rescale the input frame to improve processing speed.\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame to be rescaled\n",
    "            scale_percent: Percentage of original size (default: 50%)\n",
    "            \n",
    "        Returns:\n",
    "            Rescaled frame\n",
    "        \"\"\"\n",
    "        width = int(frame.shape[1] * scale_percent / 100)\n",
    "        height = int(frame.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        \n",
    "        # Resize image\n",
    "        resized = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
    "        return resized\n",
    "\n",
    "        \n",
    "    def process_video(self, input_source=0, output_path=None):\n",
    "        \"\"\"Process video from webcam or file\"\"\"\n",
    "        # Open video capture\n",
    "        if isinstance(input_source, int) or input_source.isdigit():\n",
    "            input_source = int(input_source)\n",
    "            print(f\"Opening webcam {input_source}\")\n",
    "        else:\n",
    "            print(f\"Opening video file: {input_source}\")\n",
    "            \n",
    "        cap = cv2.VideoCapture(input_source)\n",
    "        \n",
    "        # Check if video opened successfully\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video source {input_source}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if fps <= 0:\n",
    "            fps = 30  # Default FPS if not available\n",
    "        \n",
    "        # Create video writer if output path is specified\n",
    "        if output_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "        \n",
    "        # Initialize variables\n",
    "        frame_count = 0\n",
    "        processing_times = []\n",
    "        \n",
    "        try:\n",
    "            while cap.isOpened():\n",
    "                # Measure processing time\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Inside the while cap.isOpened() loop:\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    print(\"End of video\")\n",
    "                    break\n",
    "                \n",
    "                # Rescale frame for processing (but keep original for display/output)\n",
    "                original_frame = frame.copy()\n",
    "                processing_frame = self.rescale_frame(frame, scale_percent=50)  # Adjust percentage as needed\n",
    "                \n",
    "                # Process the smaller frame\n",
    "                features, annotated_frame = self._process_frame(processing_frame)\n",
    "                \n",
    "                # Scale the annotated frame back to original size for display\n",
    "                if annotated_frame is not None:\n",
    "                    annotated_frame = cv2.resize(annotated_frame, (frame_width, frame_height), \n",
    "                                                interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                # If no pose detected\n",
    "                if features is None:\n",
    "                    cv2.putText(frame, \"No pose detected\", (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    if output_path:\n",
    "                        out.write(frame)\n",
    "                    cv2.imshow('Squat Form Analysis', frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                    continue\n",
    "                \n",
    "                # Make prediction if enough frames collected\n",
    "                if len(self.features_buffer) >= self.window_size:\n",
    "                    new_prediction, new_confidence = self._make_prediction()\n",
    "                    self.current_prediction, self.prediction_confidence = self._smooth_predictions(\n",
    "                        new_prediction, new_confidence)\n",
    "                    if self.current_prediction is not None:\n",
    "                        self._update_error_counts(self.current_prediction)\n",
    "\n",
    "                # Update rep count with current features\n",
    "                self._update_rep_count(features)\n",
    "                \n",
    "                # Draw feedback on frame\n",
    "                result_frame = self.draw_feedback(annotated_frame, self.current_prediction, self.prediction_confidence)\n",
    "                \n",
    "                # Calculate FPS\n",
    "                processing_time = time.time() - start_time\n",
    "                processing_times.append(processing_time)\n",
    "                \n",
    "                # Only average the last 30 frames for FPS calculation\n",
    "                if len(processing_times) > 30:\n",
    "                    processing_times.pop(0)\n",
    "                \n",
    "                avg_processing_time = sum(processing_times) / len(processing_times)\n",
    "                fps_text = f\"FPS: {1/avg_processing_time:.1f}\"\n",
    "                cv2.putText(result_frame, fps_text, (frame_width - 120, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                # Write frame to output video if specified\n",
    "                if output_path:\n",
    "                    out.write(result_frame)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Squat Form Analysis', result_frame)\n",
    "                \n",
    "                # Exit on 'q' press\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "                frame_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during video processing: {e}\")\n",
    "        finally:\n",
    "            # Release resources\n",
    "            cap.release()\n",
    "            if output_path:\n",
    "                out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            print(f\"Processed {frame_count} frames\")\n",
    "            if processing_times:\n",
    "                print(f\"Average processing time: {sum(processing_times)/len(processing_times):.4f} seconds per frame\")\n",
    "\n",
    "            # Print report at the end\n",
    "            print(\"\\n\" + self.generate_report())\n",
    "            with open('report.txt', 'w') as f: f.write(self.generate_report())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bbe00-f0ac-4fff-9230-061dfc0eff37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03cdb1c-bb04-45c5-acc0-f14e6e1ad112",
   "metadata": {},
   "source": [
    "## Function to run the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7dbabc5c-04b6-4a6e-a941-a23cc170e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_squat_analyzer_jupyter(model_path='best_squat_model.keras',\n",
    "                              scaler_path='preprocessed_data_scaler.joblib',\n",
    "                              label_encoder_path='preprocessed_data_label_encoder.joblib',\n",
    "                              input_source=0,\n",
    "                              output_path=None,\n",
    "                              window_size=30):\n",
    "    \"\"\"\n",
    "    Run the squat analyzer from a Jupyter notebook\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Path to the trained model file\n",
    "    scaler_path : str\n",
    "        Path to the saved scaler\n",
    "    label_encoder_path : str\n",
    "        Path to the saved label encoder\n",
    "    input_source : int or str\n",
    "        Camera index (0 for default webcam) or path to video file\n",
    "    output_path : str or None\n",
    "        Path to save output video (None for no saving)\n",
    "    window_size : int\n",
    "        Size of the sliding window for analysis\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    analyzer : SquatAnalyzer\n",
    "        The initialized analyzer object for potential reuse\n",
    "    \"\"\"\n",
    "    # Initialize the analyzer\n",
    "    print(\"Initializing Squat Analyzer...\")\n",
    "    analyzer = SquatAnalyzer(\n",
    "        model_path=model_path,\n",
    "        scaler_path=scaler_path,\n",
    "        label_encoder_path=label_encoder_path,\n",
    "        window_size=window_size\n",
    "    )\n",
    "    \n",
    "    # Process video\n",
    "    print(f\"Starting video processing from source: {input_source}\")\n",
    "    analyzer.process_video(input_source=input_source, output_path=output_path)\n",
    "    \n",
    "    return analyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf020e3c-1524-424e-8a1c-47e32599bd36",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c76e68a-f2a4-446b-beca-e4b15b74a537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Squat Analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squat Analyzer initialized successfully\n",
      "Starting video processing from source: ./squat_video.mp4\n",
      "Opening video file: ./squat_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\fypvis\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video\n",
      "Processed 300 frames\n",
      "Average processing time: 0.1171 seconds per frame\n",
      "\n",
      "Squat Analysis Report - 2025-03-16 07:23:23\n",
      "==================================================\n",
      "Total Reps Performed: 5\n",
      "\n",
      "Form Analysis:\n",
      "--------------------\n",
      "bad_back_round: 0 occurrences (0.0%)\n",
      "  - Your back is rounding. Keep your spine neutral.\n",
      "bad_back_warp: 0 occurrences (0.0%)\n",
      "  - Your back is excessively arched. Maintain a neutral spine.\n",
      "bad_head: 28 occurrences (10.3%)\n",
      "  - Head position incorrect. Look slightly downward, keeping your neck aligned with your spine.\n",
      "bad_inner_thigh: 15 occurrences (5.5%)\n",
      "  - Knees collapsing inward. Keep knees aligned with toes.\n",
      "bad_shallow: 0 occurrences (0.0%)\n",
      "  - Squat is too shallow. Try to go deeper with proper form.\n",
      "bad_toe: 0 occurrences (0.0%)\n",
      "  - Foot positioning issue. Keep feet shoulder-width apart with toes slightly turned out.\n",
      "good: 228 occurrences (84.1%)\n",
      "  - Good form! Keep it up.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "analyzer = run_squat_analyzer_jupyter(\n",
    "    model_path='./best_squat_model.keras',\n",
    "    scaler_path='./preprocessed_data_scaler.joblib',\n",
    "    label_encoder_path='./preprocessed_data_label_encoder.joblib',\n",
    "    input_source='./squat_video.mp4',  # Use video\n",
    "    #input_source=0,  # Use webcam\n",
    "    output_path='squat_analysis_output.mp4'  # Optional output file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439e527-95e3-4295-849a-6e82baed0ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvis",
   "language": "python",
   "name": "fypvis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
